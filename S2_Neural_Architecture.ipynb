{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S2_Neural_Architecture.ipynb","provenance":[{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1595409742328}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595712343247,"user_tz":-330,"elapsed":1415,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}}},"source":["#importingg the required packages \n","          # print_function module : for print to be used as a function\n","          # torch package         : bundle for PyTorch - a python based machine learning framework \n","          #                         containing data structure for multidimentional tensors and mathematical operators  \n","          # torch.nn              : contain most of the common  function for building neural network\n","          #                         e.g.loss function like l1_loss, mse_loss, cross_entropy  and predefined layer like linear, conv2d, LSTM\n","          # torch.nn.functional   : contains functions for loss function like mse_loss, corss_entropy loss\n","          #                         and  activation functions for convolution, pooling  operations, linear layer etc.\n","          # torch.optm            : this package has implementation of various optimisation algorithm. \n","          #                         To automatically update all the model’s parameter ,call to the step() method of the optimizer object is needed\n","          # datasets , transforms : TorchVision is PyTorch’s computer vision library \n","          #                         TorchVision contains some useful datasets and models and transformation operations used in computer vision.\n","                                                            \n","from __future__ import print_function         \n","import torch                            \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms  "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wPR2OyHsvQSO","colab_type":"text"},"source":["##Defining the class for the model"]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595712343250,"user_tz":-330,"elapsed":1383,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}}},"source":["# defining a class Net which inherits the nn.Module\n","\n","class Net(nn.Module):  \n","    def __init__(self):                        \n","        super(Net, self).__init__()                   #calling parent class init\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input size 28x28 ( nMist dataset) ; OUtput size  28x28 ( due to padding) output RF : 3 x 3\n","                                                      #Input channel dimention  :1   output channel dimention: 32 \n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  #input size 28x28  ; OUtput size  28x28   output RF : 5 x 5\n","                                                      #Input channel dimention  :32   output channel dimention :64 \n","\n","        self.pool1 = nn.MaxPool2d(2, 2)               #input size 28x28  ; OUtput size  14x14    RF : 6 x 6\n","                                                      #Input channel dimention  :64   output channel dimention :64 \n","                                             \n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input size 14x14 ; OUtput size  14x14    RF : 10 x 10\n","                                                      #Input channel dimention  :64   output channel dimention :128\n","\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #input size 14x14 ; OUtput size  14x14    RF : 14 x 14\n","                                                       #Input channel dimention  :128   output channel dimention :256\n","\n","        self.pool2 = nn.MaxPool2d(2, 2)                #input size 14x14; OUtput size  7x7    RF : 16 x 16\n","                                                       #Input channel dimention  :256   output channel dimention :256\n","\n","        self.conv5 = nn.Conv2d(256, 512, 3)            #input size 7x7; OUtput size  5x5    RF : 24 x 24\n","                                                       #Input channel dimention  :256   output channel dimention :512\n","\n","        self.conv6 = nn.Conv2d(512, 1024, 3)           #input size 5x5; OUtput size  3x3    RF : 32 x 32\n","                                                       #Input channel dimention  :512   output channel dimention :1024\n","\n","        self.conv7 = nn.Conv2d(1024, 10, 3)            #input size 3x3; OUtput size  1x1    RF : 40 x 40\n","                                                       #Input channel dimention  :1024   output channel dimention :10\n","\n","        self.fc = nn.Linear(9216, 10)                                               \n","\n","    def forward(self, x):       #defining the class for the network , where x is the input\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        #x = F.relu(self.conv7(x))  ### relu discards required features ,hence not to be applied at last layer\n","        \n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","       \n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVYEybAHIrlv","colab_type":"text"},"source":["**size of image and Receptive field calculations ** as in the comment is done from the below formula\n","\n","output image size n_out = (input image size n_in + 2 * padding size - kernel_size)/ stride_size.   - 1\n","\n","Jump_in =Jump_in * Stride \n","\n","Receptive field_out = receptive field_in  + (kernel size -1)* jump_in\n","\n","  \n","  Alternatively if assumed that the receptive field is doubled when max pool the values are as below:\n","\n","  self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   #input size 28x28 ( nMist dataset) ; OUtput size  28x28 ( due to padding) output RF : 3 x 3\n","                                                      #Input channel dimention  :1   output channel dimention: 32 \n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  #input size 28x28  ; OUtput size  28x28   output RF : 5 x 5\n","                                                      #Input channel dimention  :32   output channel dimention :64 \n","\n","        self.pool1 = nn.MaxPool2d(2, 2)               #input size 28x28  ; OUtput size  14x14    RF : 10 x 10\n","                                                      #Input channel dimention  :64   output channel dimention :64 \n","                                             \n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #input size 14x14 ; OUtput size  14x14    RF : 12 x 12\n","                                                      #Input channel dimention  :64   output channel dimention :128\n","\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #input size 14x14 ; OUtput size  14x14    RF : 14 x 14\n","                                                       #Input channel dimention  :128   output channel dimention :256\n","\n","        self.pool2 = nn.MaxPool2d(2, 2)                #input size 14x14; OUtput size  7x7    RF : 28 x 28\n","                                                       #Input channel dimention  :256   output channel dimention :256\n","\n","        self.conv5 = nn.Conv2d(256, 512, 3)            #input size 7x7; OUtput size  5x5    RF : 30 x 30\n","                                                       #Input channel dimention  :256   output channel dimention :512\n","\n","        self.conv6 = nn.Conv2d(512, 1024, 3)           #input size 5x5; OUtput size  3x3    RF : 32 x 32\n","                                                       #Input channel dimention  :512   output channel dimention :1024\n","\n","        self.conv7 = nn.Conv2d(1024, 10, 3)            #input size 3x3; OUtput size  1x1    RF : 34 x 34\n","                                                       #Input channel dimention  :1024   output channel dimention :10\n"]},{"cell_type":"markdown","metadata":{"id":"W-WHdHQBIrDR","colab_type":"text"},"source":["##GPU device and plugging for torch.device \n","##verify summury for the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"status":"ok","timestamp":1595712353669,"user_tz":-330,"elapsed":11773,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}},"outputId":"3b39c483-9c76-4c39-efb3-bacdbb2d1408"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()                 #checks for GPU availability\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\") # direct to use the device GPU\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))               # summary of the model for each layer,number of parameters etc"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","            Conv2d-2           [-1, 64, 28, 28]          18,496\n","         MaxPool2d-3           [-1, 64, 14, 14]               0\n","            Conv2d-4          [-1, 128, 14, 14]          73,856\n","            Conv2d-5          [-1, 256, 14, 14]         295,168\n","         MaxPool2d-6            [-1, 256, 7, 7]               0\n","            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n","            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n","            Linear-9                   [-1, 10]          92,170\n","================================================================\n","Total params: 6,379,786\n","Trainable params: 6,379,786\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.51\n","Params size (MB): 24.34\n","Estimated Total Size (MB): 25.85\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OJKRq0Rnv6j4","colab_type":"text"},"source":["## load the test dataset and train dataset"]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595712353672,"user_tz":-330,"elapsed":11752,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}}},"source":["\n","\n","torch.manual_seed(1)  ## setting seed to make sure parameters are initialized\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}    ##  number of sub processes and memory  used for data loading\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,               ## Mnist dataset  downloaded , loaded to tensor and normalized\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)                     ## Shuffle for sub processes and memory in the batches\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1okEcPe9nsut","colab_type":"text"},"source":["##Training :\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595712353674,"user_tz":-330,"elapsed":11734,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}}},"source":["from tqdm import tqdm                                      ## tqdm is  used for displying dynamic progressbar\n","def train(model, device, train_loader, optimizer, epoch):  \n","    model.train()    \n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)  ## input and target data  devices are set\n","        optimizer.zero_grad()                              ## pytorch accumulates the gradient for backward passeses \n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()                                             ## set the mode to evaluate\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():                                    ## gradient calculation is disabled\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device) ## input and target data  devices are set\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5qTjlb-Dm6bS","colab_type":"text"},"source":["### Running  & Evaluating the model\n","\n","*   Optimizer  stochastic gradient descent(SGD)  is used to update the parameters in the network back propagation\n"]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1595712433888,"user_tz":-330,"elapsed":91933,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}},"outputId":"21e95104-3bb6-4f42-aa53-4db7daab3b25"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 3):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.07533936202526093 batch_id=468: 100%|██████████| 469/469 [00:37<00:00, 12.55it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0642, Accuracy: 9781/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.034571826457977295 batch_id=468: 100%|██████████| 469/469 [00:37<00:00, 12.65it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0385, Accuracy: 9882/10000 (99%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sb_q9UJ6x7AU","colab_type":"text"},"source":["for relu at last layer   Test set: Average loss: 1.7006, Accuracy: 3814/10000 (38%)"]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595712433896,"user_tz":-330,"elapsed":91922,"user":{"displayName":"parinita bora","photoUrl":"","userId":"11663973723666390448"}}},"source":[""],"execution_count":6,"outputs":[]}]}